{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"Hello Mr>Smith Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr>Smith Hello Mr. Smith, how are you doing today?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard\"]\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr', '>', 'Smith', 'Hello', 'Mr.', 'Smith', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', ',', 'and', 'Python', 'is', 'awesome', '.', 'The', 'sky', 'is', 'pinkish-blue', '.', 'You', 'should', \"n't\", 'eat', 'cardboard']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens=word_tokenize(example_sent)\n",
    "filter_word =[word for word in word_tokens if word not in stop_words]\n",
    "filter_word=[]\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filter_word.append(w)\n",
    "print(filter_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['august', 'and', 'september', 'are', 'a', 'wasteland', 'when', 'it', 'comes', 'to', 'children', \"'\", 's', 'films', ',', 'and', 'october', 'is', 'a', 'dumping', 'ground', 'for', 'munchkin', 'movies', 'the', 'studios', 'don', \"'\", 't', 'want', 'to', 'see', 'slaughtered', 'against', 'family', '-', 'oriented', 'thanksgiving', 'films', '.', 'last', 'year', ',', 'the', 'benevolent', 'studio', 'gods', 'gave', 'us', 'digimon', ',', 'and', 'this', 'year', ',', 'they', 'bestow', 'max', 'keeble', \"'\", 's', 'big', 'move', 'on', 'delighted', 'moviegoers', 'across', 'the', 'country', '.', 'parents', 'will', 'be', 'thrilled', 'because', 'they', \"'\", 'll', 'finally', 'have', 'something', 'to', 'drag', 'little', 'austin', 'and', 'kayla', 'to', 'see', 'that', 'doesn', \"'\", 't', 'smell', 'nearly', 'as', 'much', 'like', 'ass', 'as', 'digimon', 'did', '.', 'don', \"'\", 't', 'get', 'me', 'wrong', '-', 'keeble', ',', 'which', 'is', 'actually', 'only', 'a', '\"', 'ment', '\"', 'away', 'from', 'being', 'a', 'fetish', 'film', ',', 'isn', \"'\", 't', 'that', 'entertaining', '.', 'in', 'fact', ',', 'you', \"'\", 'd', 'be', 'better', 'off', 'waiting', 'to', 'blow', 'your', 'disposable', 'income', 'when', 'the', 'real', 'kiddie', 'pics', '(', 'monsters', ',', 'inc', '.', ',', 'harry', 'potter', ')', 'come', 'out', 'next', 'month', '.', 'but', 'if', 'dubya', 'dubya', 'iii', 'tells', 'you', 'to', 'go', 'out', 'and', 'spend', 'money', 'to', 'stimulate', 'the', 'economy', ',', 'then', 'you', \"'\", 'd', 'better', 'do', 'it', '(', 'because', 'gassing', 'up', 'the', 'minivan', 'twice', 'a', 'week', 'just', 'isn', \"'\", 't', 'going', 'to', 'cut', 'it', ')', '.', 'we', 'first', 'see', 'young', 'max', 'keeble', '(', 'alex', 'd', '.', 'linz', ',', 'home', 'alone', '3', ')', 'as', 'a', 'pint', '-', 'sized', 'superhero', ',', 'delivering', 'newspapers', 'with', 'the', 'pinpoint', 'accuracy', 'of', 'a', 'david', 'beckham', 'cross', ',', 'foiling', 'the', 'diabolical', 'plans', 'of', 'the', 'evil', 'ice', 'cream', 'man', '(', 'jamie', 'kennedy', ',', 'jay', 'and', 'silent', 'bob', 'strike', 'back', ')', 'and', 'landing', 'the', 'neighborhood', 'honey', '(', 'brooke', 'anne', 'smith', ')', ',', 'who', ',', 'by', 'the', 'way', ',', 'is', 'the', 'hottest', 'chick', 'in', 'a', 'disney', 'film', 'since', 'emmanuelle', 'chriqui', 'played', 'claire', 'boner', 'in', 'snow', 'day', '.', 'the', 'scenario', 'is', ',', 'of', 'course', ',', 'a', 'dream', '.', 'max', 'is', 'really', 'a', 'doofus', 'and', 'he', 'wakes', 'up', 'on', 'his', 'first', 'day', 'of', 'junior', 'high', 'school', 'with', 'a', 'pessimistic', 'attitude', ',', 'no', 'luck', 'with', 'the', 'ladies', 'and', 'only', 'two', 'friends', ',', 'both', 'of', 'whom', 'can', 'kindly', 'be', 'described', 'as', 'social', 'outcasts', '(', 'and', 'who', 'were', 'both', 'in', 'snow', 'day', ')', '-', 'the', 'perpetually', 'robed', 'robe', '(', 'josh', 'peck', ')', 'and', 'a', 'clarinet', '-', 'playing', 'cutie', 'named', 'megan', '(', 'summer', 'catch', \"'\", 's', 'zena', 'grey', ')', ',', 'who', 'harbors', 'secret', 'feelings', 'for', 'max', '.', 'things', 'don', \"'\", 't', 'get', 'any', 'better', 'for', 'max', 'when', 'he', 'arrives', 'at', 'school', '.', 'he', 'has', 'to', 'contend', 'with', ',', 'among', 'other', 'things', ',', 'a', 'red', '-', 'hot', 'science', 'teacher', '(', 'amber', 'valletta', ',', 'family', 'man', ')', ',', 'a', 'pair', 'of', 'polar', '-', 'opposite', 'bullies', '(', 'noel', 'fisher', 'and', 'orlando', 'brown', ')', ',', 'and', 'an', 'illiterate', 'principal', '(', 'larry', 'miller', ',', 'the', 'princess', 'diaries', ')', 'who', \"'\", 's', 'secretly', 'diverting', 'the', 'school', \"'\", 's', 'last', 'dime', 'into', 'the', 'football', 'program', '.', 'when', 'max', \"'\", 's', 'father', '(', 'grownup', 'nerd', 'robert', 'carradine', ')', 'unexpectedly', 'announces', 'the', 'family', 'is', 'moving', 'to', 'a', 'new', 'town', 'at', 'the', 'end', 'of', 'the', 'week', ',', 'max', 'decides', 'this', 'is', 'the', 'perfect', 'time', 'to', 'exact', 'revenge', 'on', 'everyone', 'who', 'pisses', 'him', 'off', '.', 'whoa', '-', 'don', \"'\", 't', 'worry', ',', 'parents', '.', 'he', 'doesn', \"'\", 't', 'do', 'it', 'klebold', '-', 'harris', 'style', '.', 'it', \"'\", 's', 'all', 'pretty', 'tame', 'stuff', ',', 'but', 'max', 'ends', 'up', 'in', 'hot', 'water', 'when', 'dad', 'nixes', 'the', 'move', ',', 'leaving', 'his', 'son', 'dangling', 'in', 'the', 'wind', 'like', 'so', 'many', 'tampon', 'strings', '.', 'director', 'tim', 'hill', '(', 'muppets', 'from', 'space', ')', 'adds', 'a', 'few', 'nice', 'touches', ',', 'like', 'max', \"'\", 's', 'voiceover', 'character', 'introductions', 'for', 'the', 'film', \"'\", 's', 'main', 'characters', 'and', 'a', 'flashback', 'scene', 'that', \"'\", 's', 'pretty', 'funny', ',', 'but', 'there', 'isn', \"'\", 't', 'too', 'much', 'else', 'happening', 'here', 'stylewise', '.', '.', '.', 'unless', 'you', 'count', 'some', 'farting', ',', 'a', 'little', 'puking', ',', 'and', 'a', 'couple', 'of', 'bizarre', 'cameos', 'from', 'tony', 'hawk', 'and', 'lil', \"'\", 'romeo', '.', '1', ':', '30', '-', 'pg', 'for', 'some', 'bullying', 'and', 'crude', 'humor'], 'neg')\n",
      "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "print(documents[1])\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "print(all_words.most_common(15))\n",
    "print(all_words[\"stupid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>colors</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>dimension</th>\n",
       "      <th>ean</th>\n",
       "      <th>keys</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sizes</th>\n",
       "      <th>upc</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>Paperwhite voyage, no regrets!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cristina M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>One Simply Could Not Ask For More</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ricky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>Great for those that just want an e-reader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tedd Gardiner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>Love / Hate relationship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dougal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>I LOVE IT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miljan David Tanic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id       asins   brand                  categories  \\\n",
       "0  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "1  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "2  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "3  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "4  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "\n",
       "  colors             dateAdded           dateUpdated  \\\n",
       "0    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "1    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "2    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "3    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "4    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "\n",
       "                  dimension  ean                         keys    ...      \\\n",
       "0  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky    ...       \n",
       "1  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky    ...       \n",
       "2  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky    ...       \n",
       "3  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky    ...       \n",
       "4  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky    ...       \n",
       "\n",
       "  reviews.rating                                 reviews.sourceURLs  \\\n",
       "0            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "1            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "2            4.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "3            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "4            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "2  I am enjoying it so far. Great for reading. Ha...   \n",
       "3  I bought one of the first Paperwhites and have...   \n",
       "4  I have to say upfront - I don't like coroporat...   \n",
       "\n",
       "                                reviews.title reviews.userCity  \\\n",
       "0              Paperwhite voyage, no regrets!              NaN   \n",
       "1           One Simply Could Not Ask For More              NaN   \n",
       "2  Great for those that just want an e-reader              NaN   \n",
       "3                    Love / Hate relationship              NaN   \n",
       "4                                   I LOVE IT              NaN   \n",
       "\n",
       "   reviews.userProvince    reviews.username  sizes upc     weight  \n",
       "0                   NaN          Cristina M    NaN NaN  205 grams  \n",
       "1                   NaN               Ricky    NaN NaN  205 grams  \n",
       "2                   NaN       Tedd Gardiner    NaN NaN  205 grams  \n",
       "3                   NaN              Dougal    NaN NaN  205 grams  \n",
       "4                   NaN  Miljan David Tanic    NaN NaN  205 grams  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\Lenovo\\Desktop\\DATA SETS\\Amazon.xlsx')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df[['reviews.text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I initially had trouble deciding between the paperwhite and the voyage because reviews more or less said the same thing: the paperwhite is great, but if you have spending money, go for the voyage.Fortunately, I had friends who owned each, so I ended up buying the paperwhite on this basis: both models now have 300 ppi, so the 80 dollar jump turns out pricey the voyage's page press isn't always sensitive, and if you are fine with a specific setting, you don't need auto light adjustment).It's been a week and I am loving my paperwhite, no regrets! The touch screen is receptive and easy to use, and I keep the light at a specific setting regardless of the time of day. (In any case, it's not hard to change the setting either, as you'll only be changing the light level at a certain time of day, not every now and then while reading).Also glad that I went for the international shipping option with Amazon. Extra expense, but delivery was on time, with tracking, and I didnt need to worry about customs, which I may have if I used a third party shipping service.\n"
     ]
    }
   ],
   "source": [
    "print(text['reviews.text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i initially had trouble deciding between the paperwhite and the voyage because reviews more or less said the same thing the paperwhite is great but if you have spending money go for the voyagefortunately i had friends who owned each so i ended up buying the paperwhite on this basis both models now have  ppi so the  dollar jump turns out pricey the voyages page press isnt always sensitive and if you are fine with a specific setting you dont need auto light adjustmentits been a week and i am loving my paperwhite no regrets the touch screen is receptive and easy to use and i keep the light at a specific setting regardless of the time of day in any case its not hard to change the setting either as youll only be changing the light level at a certain time of day not every now and then while readingalso glad that i went for the international shipping option with amazon extra expense but delivery was on time with tracking and i didnt need to worry about customs which i may have if i used a third party shipping service\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "text['Clean_Data'] = text['reviews.text'].str.lower().str.replace(\"[^a-z ]\",'')\n",
    "print(text['Clean_Data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>Clean_Data</th>\n",
       "      <th>Filter_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "      <td>initially trouble deciding paperwhite voyage r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "      <td>allow preface little history casual reader own...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>i am enjoying it so far great for reading had ...</td>\n",
       "      <td>enjoying far great reading original fire since...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>i bought one of the first paperwhites and have...</td>\n",
       "      <td>bought one first paperwhites pleased constant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>i have to say upfront  i dont like coroporate ...</td>\n",
       "      <td>say upfront dont like coroporate hermetically ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "2  I am enjoying it so far. Great for reading. Ha...   \n",
       "3  I bought one of the first Paperwhites and have...   \n",
       "4  I have to say upfront - I don't like coroporat...   \n",
       "\n",
       "                                          Clean_Data  \\\n",
       "0  i initially had trouble deciding between the p...   \n",
       "1  allow me to preface this with a little history...   \n",
       "2  i am enjoying it so far great for reading had ...   \n",
       "3  i bought one of the first paperwhites and have...   \n",
       "4  i have to say upfront  i dont like coroporate ...   \n",
       "\n",
       "                                         Filter_text  \n",
       "0  initially trouble deciding paperwhite voyage r...  \n",
       "1  allow preface little history casual reader own...  \n",
       "2  enjoying far great reading original fire since...  \n",
       "3  bought one first paperwhites pleased constant ...  \n",
       "4  say upfront dont like coroporate hermetically ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sw(text):\n",
    "    text=[word for word in text.split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "text['Filter_text']=text['Clean_Data'].apply(sw)\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tf-idf score for split words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1597x7363 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 100770 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vec =TfidfVectorizer()\n",
    "score =tf_idf_vec.fit_transform(text['Filter_text'])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>abc</th>\n",
       "      <th>abilities</th>\n",
       "      <th>abilitieswhen</th>\n",
       "      <th>ability</th>\n",
       "      <th>abit</th>\n",
       "      <th>able</th>\n",
       "      <th>aboutconclusionif</th>\n",
       "      <th>abovementioned</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zerocons</th>\n",
       "      <th>zink</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zombiesi</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zumi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  abc  abilities  abilitieswhen  ability  abit  able  aboutconclusionif  \\\n",
       "0  0.0  0.0        0.0            0.0      0.0   0.0   0.0                0.0   \n",
       "1  0.0  0.0        0.0            0.0      0.0   0.0   0.0                0.0   \n",
       "2  0.0  0.0        0.0            0.0      0.0   0.0   0.0                0.0   \n",
       "3  0.0  0.0        0.0            0.0      0.0   0.0   0.0                0.0   \n",
       "4  0.0  0.0        0.0            0.0      0.0   0.0   0.0                0.0   \n",
       "\n",
       "   abovementioned  absolute  ...   zen  zero  zerocons  zink  zip  zippy  \\\n",
       "0             0.0       0.0  ...   0.0   0.0       0.0   0.0  0.0    0.0   \n",
       "1             0.0       0.0  ...   0.0   0.0       0.0   0.0  0.0    0.0   \n",
       "2             0.0       0.0  ...   0.0   0.0       0.0   0.0  0.0    0.0   \n",
       "3             0.0       0.0  ...   0.0   0.0       0.0   0.0  0.0    0.0   \n",
       "4             0.0       0.0  ...   0.0   0.0       0.0   0.0  0.0    0.0   \n",
       "\n",
       "   zombiesi  zoom  zooming  zumi  \n",
       "0       0.0   0.0      0.0   0.0  \n",
       "1       0.0   0.0      0.0   0.0  \n",
       "2       0.0   0.0      0.0   0.0  \n",
       "3       0.0   0.0      0.0   0.0  \n",
       "4       0.0   0.0      0.0   0.0  \n",
       "\n",
       "[5 rows x 7363 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe of words and respective TF-IDF score\n",
    "\n",
    "df_tf_idf = pd.DataFrame(score.toarray(),columns=tf_idf_vec.get_feature_names())\n",
    "df_tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word and their Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>kindle</td>\n",
       "      <td>60.522642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>great</td>\n",
       "      <td>56.489598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>fire</td>\n",
       "      <td>53.514421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>like</td>\n",
       "      <td>47.409148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6015</th>\n",
       "      <td>sound</td>\n",
       "      <td>47.312267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Words      Score\n",
       "3547  kindle  60.522642\n",
       "2814   great  56.489598\n",
       "2431    fire  53.514421\n",
       "3709    like  47.409148\n",
       "6015   sound  47.312267"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_tf_idf = df_tf_idf.sum()\n",
    "words_tf_idf=pd.DataFrame(words_tf_idf).reset_index()\n",
    "words_tf_idf=words_tf_idf.rename(columns={'index':'Words',0:'Score'})\n",
    "words_tf_idf=words_tf_idf.sort_values(by='Score',ascending=False)\n",
    "Top-10_words_tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1597x44036 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 128389 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Bigram=\n",
    "tf_idf_bigram = TfidfVectorizer(ngram_range=(2,2))\n",
    "score_bigram = tf_idf_bigram.fit_transform(text['Filter_text'])\n",
    "score_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19809</th>\n",
       "      <td>kindle fire</td>\n",
       "      <td>21.049710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13656</th>\n",
       "      <td>fire hd</td>\n",
       "      <td>15.838693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>apples buds</td>\n",
       "      <td>13.341446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13748</th>\n",
       "      <td>fire tv</td>\n",
       "      <td>12.459168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>amazon prime</td>\n",
       "      <td>9.720496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word      Score\n",
       "19809   kindle fire  21.049710\n",
       "13656       fire hd  15.838693\n",
       "2418    apples buds  13.341446\n",
       "13748       fire tv  12.459168\n",
       "1724   amazon prime   9.720496"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe of words and respective TF-IDF score\n",
    "\n",
    "df_tf_idf_bigram = pd.DataFrame(score_bigram.toarray(), columns=tf_idf_bigram.get_feature_names())\n",
    "\n",
    "df_tf_idf_bigram\n",
    "\n",
    "# Word and they score\n",
    "\n",
    "words_score_tf_idf_bigram = df_tf_idf_bigram.sum()\n",
    "\n",
    "words_score_tf_idf_bigram = pd.DataFrame(words_score_tf_idf_bigram).reset_index()\n",
    "\n",
    "words_score_tf_idf_bigram = words_score_tf_idf_bigram.rename(columns={\"index\" : 'Word', 0 : \"Score\"})\n",
    "\n",
    "words_score_tf_idf_bigram.sort_values(by = 'Score', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the package\n",
    "\n",
    "#!pip install vaderSentiment\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "senti = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to get the polarity for each review\n",
    "\n",
    "text_polarity = lambda text: senti.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.9804\n",
       "1    0.9874\n",
       "2    0.4364\n",
       "3    0.9743\n",
       "4    0.9930\n",
       "Name: reviews.text, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['reviews.text'].head().apply(text_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>Clean_Data</th>\n",
       "      <th>Filter_text</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "      <td>initially trouble deciding paperwhite voyage r...</td>\n",
       "      <td>0.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "      <td>allow preface little history casual reader own...</td>\n",
       "      <td>0.9874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>i am enjoying it so far great for reading had ...</td>\n",
       "      <td>enjoying far great reading original fire since...</td>\n",
       "      <td>0.4364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>i bought one of the first paperwhites and have...</td>\n",
       "      <td>bought one first paperwhites pleased constant ...</td>\n",
       "      <td>0.9743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>i have to say upfront  i dont like coroporate ...</td>\n",
       "      <td>say upfront dont like coroporate hermetically ...</td>\n",
       "      <td>0.9930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "2  I am enjoying it so far. Great for reading. Ha...   \n",
       "3  I bought one of the first Paperwhites and have...   \n",
       "4  I have to say upfront - I don't like coroporat...   \n",
       "\n",
       "                                          Clean_Data  \\\n",
       "0  i initially had trouble deciding between the p...   \n",
       "1  allow me to preface this with a little history...   \n",
       "2  i am enjoying it so far great for reading had ...   \n",
       "3  i bought one of the first paperwhites and have...   \n",
       "4  i have to say upfront  i dont like coroporate ...   \n",
       "\n",
       "                                         Filter_text  Polarity  \n",
       "0  initially trouble deciding paperwhite voyage r...    0.9804  \n",
       "1  allow preface little history casual reader own...    0.9874  \n",
       "2  enjoying far great reading original fire since...    0.4364  \n",
       "3  bought one first paperwhites pleased constant ...    0.9743  \n",
       "4  say upfront dont like coroporate hermetically ...    0.9930  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['Polarity']=text['reviews.text'].apply(text_polarity)\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEaZJREFUeJzt3X+MZWV9x/H3R7Zg1SgLrHRdqAtxq5I2VTKhVBN/YRSwcWkK7ZpaV7vNRkutLW3qWpvY2DSFpilq2mC3gkJrFEQN24o1Kz9imgh1qYoixR3RwsrKjuWHtUYU/faP+4xed2d2ZufeubPL834lk3vOc55zznefe/d+5vy4d1JVSJL687iVLkCStDIMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnVq10AQdzwgkn1Pr161e6DEk6otx2223frKo1C/U7rANg/fr17Nq1a6XLkKQjSpL/Xkw/TwFJUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDutPAkvSSlq/7WMrtu+vXfyKZd+HRwCS1CkDQJI6tWAAJLkiyb4kXxxqOy7JziS72+Pq1p4k70oyneT2JKcPrbO59d+dZPPy/HMkSYu1mCOA9wFn79e2DbihqjYAN7R5gHOADe1nK3AZDAIDeBvwS8AZwNtmQ0OStDIWDICq+hTwwH7NG4Er2/SVwHlD7VfVwC3AsUnWAi8HdlbVA1X1ILCTA0NFkjRBS70GcGJV7QVoj09t7euAe4f67Wlt87VLklbIuC8CZ462Okj7gRtItibZlWTXzMzMWIuTJP3YUgPg/nZqh/a4r7XvAU4e6ncScN9B2g9QVduraqqqptasWfAvmkmSlmipAbADmL2TZzNw3VD7a9rdQGcCD7dTRJ8AXpZkdbv4+7LWJklaIQt+EjjJB4AXASck2cPgbp6LgWuSbAHuAS5o3a8HzgWmge8ArwOoqgeS/AXwmdbv7VW1/4VlSdIELRgAVfWqeRadNUffAi6cZztXAFccUnWSpGXjJ4ElqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUSAGQ5A+T3JHki0k+kOTxSU5JcmuS3UmuTnJ063tMm59uy9eP4x8gSVqaJQdAknXA7wNTVfXzwFHAJuAS4NKq2gA8CGxpq2wBHqyqZwCXtn6SpBUy6imgVcBPJ1kFPAHYC7wEuLYtvxI4r01vbPO05WclyYj7lyQt0ZIDoKq+DvwNcA+DN/6HgduAh6rq0dZtD7CuTa8D7m3rPtr6H7/U/UuSRjPKKaDVDH6rPwV4GvBE4Jw5utbsKgdZNrzdrUl2Jdk1MzOz1PIkSQsY5RTQS4GvVtVMVX0f+AjwPODYdkoI4CTgvja9BzgZoC1/CvDA/hutqu1VNVVVU2vWrBmhPEnSwYwSAPcAZyZ5QjuXfxbwJeAm4PzWZzNwXZve0eZpy2+sqgOOACRJkzHKNYBbGVzM/U/gC21b24E3AxclmWZwjv/ytsrlwPGt/SJg2wh1S5JGtGrhLvOrqrcBb9uv+W7gjDn6fhe4YJT9SZLGx08CS1KnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqZECIMmxSa5N8l9J7kzyy0mOS7Izye72uLr1TZJ3JZlOcnuS08fzT5AkLcWoRwDvBP6tqp4F/CJwJ7ANuKGqNgA3tHmAc4AN7WcrcNmI+5YkjWDJAZDkycALgMsBqup7VfUQsBG4snW7EjivTW8ErqqBW4Bjk6xdcuWSpJGMcgRwKjADvDfJZ5O8J8kTgROrai9Ae3xq678OuHdo/T2tTZK0AkYJgFXA6cBlVfVc4P/48emeuWSOtjqgU7I1ya4ku2ZmZkYoT5J0MKMEwB5gT1Xd2uavZRAI98+e2mmP+4b6nzy0/knAfftvtKq2V9VUVU2tWbNmhPIkSQez5ACoqm8A9yZ5Zms6C/gSsAPY3No2A9e16R3Aa9rdQGcCD8+eKpIkTd6qEdd/I/D+JEcDdwOvYxAq1yTZAtwDXND6Xg+cC0wD32l9JUkrZKQAqKrPAVNzLDprjr4FXDjK/iRJ4+MngSWpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6tTIAZDkqCSfTfKvbf6UJLcm2Z3k6iRHt/Zj2vx0W75+1H1LkpZuHEcAbwLuHJq/BLi0qjYADwJbWvsW4MGqegZwaesnSVohIwVAkpOAVwDvafMBXgJc27pcCZzXpje2edrys1p/SdIKGPUI4B3AnwA/bPPHAw9V1aNtfg+wrk2vA+4FaMsfbv0lSStgyQGQ5FeAfVV123DzHF1rEcuGt7s1ya4ku2ZmZpZaniRpAaMcATwfeGWSrwEfZHDq5x3AsUlWtT4nAfe16T3AyQBt+VOAB/bfaFVtr6qpqppas2bNCOVJkg5myQFQVW+pqpOqaj2wCbixqn4TuAk4v3XbDFzXpne0edryG6vqgCMASdJkLMfnAN4MXJRkmsE5/stb++XA8a39ImDbMuxbkrRIqxbusrCquhm4uU3fDZwxR5/vAheMY3+SpNH5SWBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjq15ABIcnKSm5LcmeSOJG9q7ccl2Zlkd3tc3dqT5F1JppPcnuT0cf0jJEmHbpQjgEeBP6qqZwNnAhcmOQ3YBtxQVRuAG9o8wDnAhvazFbhshH1Lkka0aqkrVtVeYG+b/t8kdwLrgI3Ai1q3K4GbgTe39quqqoBbkhybZG3bjiTNa/22j610CY9JY7kGkGQ98FzgVuDE2Tf19vjU1m0dcO/QantamyRpBYwcAEmeBHwY+IOq+tbBus7RVnNsb2uSXUl2zczMjFqeJGkeIwVAkp9i8Ob//qr6SGu+P8natnwtsK+17wFOHlr9JOC+/bdZVduraqqqptasWTNKeZKkgxjlLqAAlwN3VtXfDi3aAWxu05uB64baX9PuBjoTeNjz/5K0cpZ8ERh4PvBbwBeSfK61/SlwMXBNki3APcAFbdn1wLnANPAd4HUj7FuSNKJR7gL6d+Y+rw9w1hz9C7hwqfuTJI2XnwSWpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpU6P8QRhJnVm/7WMrXYLGyCMASeqUASBJnTIAJKlTBoAkdcoAkKROeReQjmgreVfK1y5+xYrtWxoHjwAkqVMGgCR1ygCQpE4ZAJLUKS8CS0cYv45B4+IRgCR16jF9BLBSvyl5e6CkI8FjOgB64z3xk+WpGB3pDACNhW+G0pFn4gGQ5GzgncBRwHuq6uJJ17DcfDOUdCSY6EXgJEcBfw+cA5wGvCrJaZOsQZI0MOm7gM4Apqvq7qr6HvBBYOOEa5AkMfkAWAfcOzS/p7VJkiZs0tcAMkdb/USHZCuwtc1+O8ldi9juCcA3R6xtuVjboTtc6wJrW4rDtS44jGvLJSPV9vTFdJp0AOwBTh6aPwm4b7hDVW0Hth/KRpPsqqqp0csbP2s7dIdrXWBtS3G41gXWNulTQJ8BNiQ5JcnRwCZgx4RrkCQx4SOAqno0ye8Bn2BwG+gVVXXHJGuQJA1M/HMAVXU9cP2YN3tIp4wmzNoO3eFaF1jbUhyudUHntaWqFu4lSXrM8dtAJalTR0wAJLkgyR1Jfphk3ivjSc5OcleS6STbhtpPSXJrkt1Jrm4XocdV23FJdrZt70yyeo4+L07yuaGf7yY5ry17X5KvDi17zqTqav1+MLTvHUPtKz1mz0ny6fa8357kN4aWjX3M5nvtDC0/po3DdBuX9UPL3tLa70ry8lFrOcS6LkrypTZGNyR5+tCyOZ/bCdb22iQzQzX8ztCyze35351k8wrUdulQXV9O8tDQsmUbtyRXJNmX5IvzLE+Sd7W6b09y+tCy8Y5ZVR0RP8CzgWcCNwNT8/Q5CvgKcCpwNPB54LS27BpgU5t+N/CGMdb218C2Nr0NuGSB/scBDwBPaPPvA85fhjFbVF3At+dpX9ExA34O2NCmnwbsBY5djjE72GtnqM/vAu9u05uAq9v0aa3/McApbTtHTbCuFw+9lt4wW9fBntsJ1vZa4O/mWPc44O72uLpNr55kbfv1fyODm1ImMW4vAE4HvjjP8nOBjzP43NSZwK3LNWZHzBFAVd1ZVQt9KGzOr5pIEuAlwLWt35XAeWMsb2Pb5mK3fT7w8ar6zhhrmMuh1vUjh8OYVdWXq2p3m74P2AesGWMNwxbzNSXDNV8LnNXGaSPwwap6pKq+Cky37U2krqq6aei1dAuDz9dMwihf7fJyYGdVPVBVDwI7gbNXsLZXAR8Y4/7nVVWfYvAL4Hw2AlfVwC3AsUnWsgxjdsQEwCLN91UTxwMPVdWj+7WPy4lVtRegPT51gf6bOPDF9pftcO/SJMdMuK7HJ9mV5JbZ01IcZmOW5AwGv8l9Zah5nGO2mK8p+VGfNi4PMxin5fyKk0Pd9hYGvz3Omuu5HZfF1vZr7Xm6NsnsB0GX+2thFr39dsrsFODGoeblHLeFzFf72MfssPp7AEk+CfzMHIveWlXXLWYTc7TVQdrHUtshbmct8AsMPgsx6y3ANxi8wW0H3gy8fYJ1/WxV3ZfkVODGJF8AvjVHv5Ucs38CNlfVD1vzksdsvt3M0bb/v3fZXl8HsehtJ3k1MAW8cKj5gOe2qr4y1/rLVNu/AB+oqkeSvJ7BEdRLFrnuctc2axNwbVX9YKhtOcdtIRN7nR1WAVBVLx1xE/N91cQ3GRxGrWq/uR3wFRSj1Jbk/iRrq2pve7Pad5BN/Trw0ar6/tC297bJR5K8F/jjSdbVTq9QVXcnuRl4LvBhDoMxS/Jk4GPAn7XD4dltL3nM5rHg15QM9dmTZBXwFAaH8otZdznrIslLGQTrC6vqkdn2eZ7bcb2RLearXf5naPYfgUuG1n3RfuvePKa6FlXbkE3AhcMNyzxuC5mv9rGP2WPtFNCcXzVRgysoNzE49w6wGVjMEcVi7WjbXMy2DzjX2N4AZ8+7nwfMeXfActSVZPXs6ZMkJwDPB750OIxZew4/yuB86If2WzbuMVvM15QM13w+cGMbpx3ApgzuEjoF2AD8x4j1LLquJM8F/gF4ZVXtG2qf87kdU12LrW3t0OwrgTvb9CeAl7UaVwMv4yePipe9tlbfMxlcUP30UNtyj9tCdgCvaXcDnQk83H7hGf+YLdeV7nH/AL/KIAEfAe4HPtHanwZcP9TvXODLDNL6rUPtpzL4TzkNfAg4Zoy1HQ/cAOxuj8e19ikGf/Vstt964OvA4/Zb/0bgCwzexP4ZeNKk6gKe1/b9+fa45XAZM+DVwPeBzw39PGe5xmyu1w6D00qvbNOPb+Mw3cbl1KF139rWuws4Z8yv/YXq+mT7PzE7RjsWem4nWNtfAXe0Gm4CnjW07m+3sZwGXjfp2tr8nwMX77feso4bg18A97bX9h4G121eD7y+LQ+DP5z1lbb/qaF1xzpmfhJYkjr1WDsFJElaJANAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKRO/T/8+XjJUMdOpQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(text['Polarity'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing the polarity range\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sentiment_mapping = {1:'Very Bad', 2:'bad', 3:'netural', 4:'good', 5:'very good'}\n",
    "\n",
    "map_sentiment = lambda val: np.digitize(val,[-1, -0.5, -0.2, 0.2, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>Clean_Data</th>\n",
       "      <th>Filter_text</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "      <td>initially trouble deciding paperwhite voyage r...</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>5</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "      <td>allow preface little history casual reader own...</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>5</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>i am enjoying it so far great for reading had ...</td>\n",
       "      <td>enjoying far great reading original fire since...</td>\n",
       "      <td>0.4364</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>i bought one of the first paperwhites and have...</td>\n",
       "      <td>bought one first paperwhites pleased constant ...</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>5</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>i have to say upfront  i dont like coroporate ...</td>\n",
       "      <td>say upfront dont like coroporate hermetically ...</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>5</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "2  I am enjoying it so far. Great for reading. Ha...   \n",
       "3  I bought one of the first Paperwhites and have...   \n",
       "4  I have to say upfront - I don't like coroporat...   \n",
       "\n",
       "                                          Clean_Data  \\\n",
       "0  i initially had trouble deciding between the p...   \n",
       "1  allow me to preface this with a little history...   \n",
       "2  i am enjoying it so far great for reading had ...   \n",
       "3  i bought one of the first paperwhites and have...   \n",
       "4  i have to say upfront  i dont like coroporate ...   \n",
       "\n",
       "                                         Filter_text  Polarity  \\\n",
       "0  initially trouble deciding paperwhite voyage r...    0.9804   \n",
       "1  allow preface little history casual reader own...    0.9874   \n",
       "2  enjoying far great reading original fire since...    0.4364   \n",
       "3  bought one first paperwhites pleased constant ...    0.9743   \n",
       "4  say upfront dont like coroporate hermetically ...    0.9930   \n",
       "\n",
       "   sentiment_category      label  \n",
       "0                   5  very good  \n",
       "1                   5  very good  \n",
       "2                   4       good  \n",
       "3                   5  very good  \n",
       "4                   5  very good  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a column of sentiment_category in the data\n",
    "\n",
    "text['sentiment_category'] = text['Polarity'].apply(map_sentiment)\n",
    "\n",
    "# We need to replace the Sentiment category values by labels\n",
    "\n",
    "text['label'] = text['sentiment_category'].replace(sentiment_mapping)\n",
    "\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
