{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'),\n",
       " ('welcome', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('learning', 'VBG'),\n",
       " ('Categoizing', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Pos', 'NNP'),\n",
       " ('tagging', 'VBG'),\n",
       " ('with', 'IN'),\n",
       " ('NLTK', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Python', 'NNP')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "text=word_tokenize(\"Hello welcome to the world of learning Categoizing and Pos tagging with NLTK and Python\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Categoizing', 'Pos', 'NLTK', 'Python']\n"
     ]
    }
   ],
   "source": [
    "#Printing only nouns from the text:\n",
    "is_noun=lambda x:x[:3]=='NNP'\n",
    "nouns=[word for(word,x) in pos_tag(text) if is_noun(x)]\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create the topic modelling of only nouns from the newspaper data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data from sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "sub_category = ['comp.sys.mac.hardware', 'rec.autos', 'sci.space', 'misc.forsale','talk.politics.guns']\n",
    "\n",
    "news_group=fetch_20newsgroups(categories=sub_category,remove=('headers','footers','quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_raw=news_group.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(docs_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n740 Turbo in UK was good for 124mph. Useful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am looking for a working docking deck (deck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n &gt;In article &lt;1993Apr19.020359.26996@sq.sq.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A few posts back, somebody mentioned that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nIt still applies, except the astro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Raw_text\n",
       "0  \\n740 Turbo in UK was good for 124mph. Useful ...\n",
       "1  I am looking for a working docking deck (deck ...\n",
       "2  \\n >In article <1993Apr19.020359.26996@sq.sq.c...\n",
       "3  A few posts back, somebody mentioned that the ...\n",
       "4  \\n\\n\\n\\n\\n\\nIt still applies, except the astro..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.rename(columns={0:'Raw_text'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only words\n",
    "doc = df['Raw_text'].str.lower().str.replace('[^a-z ]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    turbo uk good mph useful blowing away vw beetl...\n",
       "1    looking working docking deck deck goes back of...\n",
       "2    article aprsqsqcom msbsqsqcom mark brader mb t...\n",
       "3    posts back somebody mentioned duo might crash ...\n",
       "4    still applies except astronomy days long basel...\n",
       "Name: Raw_text, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets remove the stop words:\n",
    "stop=set(stopwords.words('english'))\n",
    "def sw(text):\n",
    "    text=[word for word in text.split() if word not in stop]\n",
    "    #joining the list of words with space seperator\n",
    "    return \" \".join(text)\n",
    "doc_clean=doc.apply(sw)\n",
    "doc_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will try to create the topic modelling only using nouns so that we have a bit more clear idea what topics are all about\n",
    "# creating the user define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns(x):\n",
    "    is_noun=lambda x:x[:3]=='NN'\n",
    "    tokenized=word_tokenize(x)\n",
    "    all_noun=[word for (word,x) in pos_tag(tokenized) if is_noun(x)]\n",
    "    return \" \".join(all_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_finall=doc_clean.apply(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 turbo mph beetle doubt car volvo car\n",
       "1    deck deck jvc gxs tube video camera format ple...\n",
       "2    article aprsqsqcom msbsqsqcom mark brader mb f...\n",
       "3    somebody duo hasthe kind duo software whichwil...\n",
       "4    astronomy nasas observatorys source rotation t...\n",
       "Name: Raw_text, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_finall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2896, 1105)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the LDA model again with new DTM which contain only Nouns\n",
    "\n",
    "vec_noun = CountVectorizer(max_df=.3,min_df=10)\n",
    "dtm_noun = vec_noun.fit_transform(doc_finall)\n",
    "dtm_noun.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the LDA model\n",
    "lda_model_noun = LatentDirichletAllocation(n_components=5, max_iter=50)\n",
    "# Fitting the model on dtm\n",
    "lda_output_noun = lda_model_noun.fit_transform(dtm_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
